welcome back everyone
in previous video we looked at how you
actually store data on on computer hard
drives and things like that
and in this video i'm going to continue
on that theme and we're going to look a
bit more
at file formats i'm going to look at how
numbers are actually represented in
computers and how you might store those
we're going to look at a bit about
strings and so generally speaking we're
going to look at how you might
represent and store data and
that makes a big difference when you're
trying to do things like saving the data
from your game to disk
or when you're trying to communicate
information across a network you have to
say
how are we going to represent that data
while it's in transit
so quite a lot to talk about so let's
get started
okay so let's start by looking at text
files now
text files are not all that exciting but
i've experienced that there's a lot of
confusion so what actually
is a text file so let's look at a text
file that you're likely to have seen
before
here's a microsoft word file and
all it has in this file is the text
hello world
so so i saved that as a doc file how
large is that doc file
hello world.doc well um
22 kilobytes to save
hello world so there must be something
in there that is not just the text of
hello world
and the question is what is it so
well if we can open it up in our
favorite text editor
um ah well it's a binary file and
emacs doesn't do a terribly good job at
editing binary files because it's a text
editor
so what else could we do um there's a
simple utility called strings
and what this does is it searches
through binary files trying to find
anything that looks like an ascii or
similar string
and print it out so let's run that over
our word file
and you can see that there's lots of
stuff in here to do with
versionings bits of stuff to do with
themes and so forth
if i scroll back up finally up there is
my
text hello world and there's some other
stuff here too
some secret text from an old edit hmm
actually it turns out that microsoft
word can do all sorts of fancy things
including track changes and if i
highlight the changes
in the file there can be hidden text in
there
like the text i deleted from the
previous edit
so there's lots of things that can
actually make itself into a a word file
now as an aside you should probably
never send people
word files if you actually might have
anything sensitive in them i once
received a
a cv from someone that when i
when track changes was on revealed
itself to actually have a whole bunch of
comments from people who had actually
reviewed previous versions of the cv
so you probably don't want that um so a
microsoft word file is definitely
not just a text file there's a lot of
other capabilities that are occurring
there including
lots of stuff to do with presentation
fonts and things like that
now it's actually a strange format
really
it includes an awful lot of basically a
memory dump of internal data structures
within within microsoft word and so it's
not really a very good format
for for microsoft being able to continue
to develop the
the um and going forward
so at some point microsoft decided to
actually move to a much more
modern file format and so you also
instead of not just having doc you have
the docx file format
so if we save the whole thing as a docx
file instead
then that's actually about half the size
and so what's a docx file look like in
our
text editor um
that's probably what not what you
expected it to do
when i went to open the file it's
actually presenting it
as a directory of lots of other files
and the reason for this is that actually
a microsoft word docx file
is a zip file of a whole bunch of other
files
and emacs being quite a capable editor
knows a zip file when it sees it and
decides to try and open it and present
me what's inside it
and so we can actually look through here
and we can see the different uh
pieces of content for the document
settings and things like that and if i
open
this particular one the document itself
what we have in here is an xml file
which looks very similar to html
it's all these things within angle
brackets
and way down in the bottom here is hello
world
um in amongst all the formatting stuff
it seems to require an awful lot of
formatting stuff to not
actually do any formatting um and also
the
the deleted text is still in there as
well and so
there's this is it actually at least
it's now a
documented text file format for how to
do word processing
whereas the actual doc file is not at
all but both of these are way
more complicated than we really want to
think of when we're actually just
thinking of a text file
these are proper full word processor
file formats the docx file is a
reasonable um word processor file format
the doc file is a pretty
insane um word processor file format
but neither of them are really what i
would recall a text file format
things that just contain text
so if word processor files are not
really text files
as such then can we persuade word to
actually do a better job of creating a
text file
well it turns out we can all we have to
do is ask it
if we do save as and we specify that
it's a plain text file without any
adornments
what are we going to get well
what we're going to get is actually
quite a lot of options
word says it can save it as a mac text
encoding or
a ms-dos word encoding or actually lots
of other things too
so let's start off with saving it as a
mac
text encoding and see what that gives us
okay so let's look at that in an actual
text editor
and there we go we have hello world
just the text nothing else and down the
bottom it says that it's a mac file
i wonder how it knows
so what happens if we decide to change
it as a so as a dos file instead
so we can still save it as a plain text
file
we can replace it and say it's now a
microsoft
file instead so what's the difference
by emac open it in emacs we still see
exactly the same text
hello world but now down the bottom it
says it's a dos file
so even though these two text files look
the same in an actual text editor
they're not quite the same and so the
question is how do they differ
well let's actually just look at what's
stored in the file
utility od for doctor dump minus a says
display the actual ascii characters in
each position in the file
and what we can see is that we have
hello
space and carriage return a new line
and then world and then at the end a
carriage return and a new line character
and so even though we've got a a
ascii text file here with nothing fancy
no
internationalization or anything like
that when we saved it as a
dos file we got carriage return and new
line for each of those new lines
but if we save it instead as a
mac file
what do we get we get a different line
ending by default carriage return only
on
on macos
and we can see now that the new line
characters which previously for for
windows type machines were
character new line for macs and lots of
other
unix type systems would just use
carriage return in there instead
so even how you do line endings in a
basic text file
actually depends on conventions of the
different computers you might actually
be working on
and so we have two different formats
just for how we do
new line endings in files so you really
have to know what the encoding is for
your file in order to be able to
actually understand what the contents
are
so what we've looked at so far the the
words hello world
are a very anglo-centric example
they they use characters which are
represented in
a code called ascii the american
standard code for information
interchange
and until the 1990s this was pretty much
the way
most computers actually represented data
and if you came from some different
background you were a bit stuck
do we have other ways of doing this well
first of all let's
have a look at what ascii is and then
we'll see how you might extend that
to cope with other languages so
ascii is basically a standard for how
you map
individual characters to the numbers
that you store
in bytes in your computer to represent
those
and so ascii dates from the 1960s
and there are codes to store all
of the usual characters in the english
alphabet
all the way through from a to z and
there are codes to store numbers
and there are codes to store things like
quotation marks or exclamation marks
but this is really an american view of
the world so although there's a dollar
symbol in here
there's no symbols in here for pounds
there's no symbols in here for euros and
there's certainly no symbols in here for
emoji
so how might we go away representing
things that are beyond
basic ascii well
what we have here is a table of 127
different values and so we need only
seven bits to store 127 values
and so we've got an extra bit there so
maybe in each byte
we could use the upper half of the range
from
number 128 up to 255 to store some other
values
so that's actually what a different
bunch of different standards did for how
to actually extend
internationalization beyond just the
english language characters
so there are a set of standards to
extend ascii
out to other areas of the world this set
of standards
or one of the sets of standards is iso
8859
and the what this does is it uses all of
those
upper characters in the in the each byte
the numbers from 128 up to 255 in order
to be able to store other things
now the problem is there's a lot of
languages in the world and a lot of
characters you might want to store
and so there isn't really enough space
in the
upper half of your bite only another 127
characters
so what they did was to define a whole
bunch of variants
iso 8a59 part 1 does
western european languages and so if you
look in
the the tables for this we can see that
the
lower half of the encodings are just
exactly what you'd expect from
ascii characters on the upper half of
the encodings in a
an 8059 part one are good for western
european languages so if you're french
or
danish or german you can find all of the
accented characters you need in here
but if you're not western european then
you're a bit out of luck there so there
are different variants of it for
different languages so part 7 for
example
covers encodings for greek and so now
the
upper half of the encodings for each
byte would encode greek characters and
so forth
so this lets you encode quite a lot of
additional languages
just within one byte per character
but that's still not really enough for
encoding languages like chinese and
japanese
where you have an awful lot more
characters you need to be able to encode
so at some point you're going to have to
give up on the idea of storing
a single character in a single bite of
memory and use something a bit richer
so the solution to this problem is
unicode
what unicode is is a great big
table of every character from pretty
much every language that you might ever
come across
it's 159 different scripts that are
represented
ranging all the way from english to thai
to
chinese japanese and so forth and for
every possible character you might
represent from any of those scripts
there's a mapping from that character to
a specific
number which is used to represent that
character in the computer
so for example here the um
the symbol pi is represented by this
particular number and this in
hexadecimal
is 3 c 0 and that particular number
will represent pi no matter where you
come across it wherever unicode is used
so we've got all these different
characters
all these different characters from all
these different languages but
of course they didn't stop there they
they went on and included emoji as well
and so that unicode is also has a
mapping for every emoji you might want
and as a whole standardization
consortium that
is devoted to registering
um new emoji and and how they are
represented and things like that
but if you want to store for example to
represent in your computer say a smiley
face like this one
then the numeric representation that's
used to store that number
is going to be in hexadecimal one f 600
and that will then be used to represent
that smiley face wherever you come
across it
if there's a number for every character
can we use those characters
in our python code well it turns out yes
you can
python 3 is unicode aware and all
strings are
unicode so we can actually just enter
unicode characters directly into our
python programs
now of course we still have to have a
way of getting those characters
into the program here and emacs doesn't
have a fancy way of doing that but
i can actually just do insert character
and i can type in the
hexadecimal code for the particular
character i want to insert
so if i want to have say a hand doing a
vulcan live long or prosperous salute
there's a unicode character for that and
we can run that
and so what i have here have to define
straw one to be hello
live long and prosper and i can print
that out and i can print out the length
of the string we can see what that does
and it does what we'd expect it actually
just prints out absolutely fine and
the length of that string is six
characters
now we're not quite done there because
actually
unicode's slightly more complex than
that let me show you another example
because whilst there is a a charac
code for every character you want to be
able to represent
there's also modifier characters as well
so
i can insert
another unicode character in this case
let's do
uh 1f 3 f
b because my hand isn't yellow my hand
is sort of pasty white and then get a
pasty white hand
or if you're
want to represent a different skin color
there's there are
unicode modifiers for all the different
skin colors or at least a reasonable
range of them
on f3 f e
is a slightly darker skin color and so
forth and so you can
personalize your emoji to to match
what's appropriate for what you're
trying to represent
now the question
we have remaining here is okay so if
python thinks that is six characters
what do you think that is well
let's try and run it
and here is where it starts to get a
little bit more complicated that is six
characters i think we'd agree that's
probably six characters but that's seven
characters
and the reason for that is that there's
still
actually the vulcan hand symbol
and the unicode modifier character in
there and even though you can't see them
they're actually there and so this is
where you have to be really quite
careful to understand what's going on in
terms of the way the strings and things
are encoded if you want to understand
how much screen space is it going to
take to take this well
it's not obvious is it it's not easy to
know exactly how that's going to be
represented
that's where things get a little bit
complicated
so how are these characters actually
represented
in this python file or in
other text files for that matter well
originally unicode was designed with the
idea that
each character would occupy two bytes of
the file
but they pretty rapidly ran out of space
because in two bytes you can only store
two to the sixteen values or six
five five three five and we currently
have a hundred and forty four thousand
possible characters so you're obviously
going to need
more than that and so the canonical
representation for unicode
typically is destroyed in a in a 32-bit
integer for each of these values
which would be fine except for it's not
very efficient and so
the question then is well how do we
store them more efficiently
but there's also another problem which
is an awful lot of stuff
actually still uses ascii as it's sort
of a baseline
so for example our python program here
i was just editing a python program and
i stuck some unicode in it
but my python program when i was editing
it was ascii text
with one byte per character and i've
just gone and stuff some unicode
characters into there
so what happened did the whole file
suddenly expand to four bytes per
character
well no that's not what happened so let
me just trim this out so we've just got
the hello
and the other characters in there and
we'll look at that in in od
oops one too many okay
so now we've just got the hello and then
the two hands
okay so what does that look like when we
actually look at the
uh what's what's stored in each of the
bytes of the file
we can see that hello is stored with one
character per byte
just in standard ascii there's nothing
unusual going on there
but then when we get to the the vulcan
hand symbol
we're no longer an ascii and what we
have here is
is four bytes that are used to store
that vulcan hand symbol
we've got a new line we've got the next
hello and then we've got the same four
bytes
storing the second vulcan hand symbol
and then another four bytes
which are storing the skin color
modifier for that vulcan hand symbol
and so what we have here is something
that's quite interesting we have
some characters are represented by a
single byte and some characters are
represented by four bytes
so obviously what we're going on here is
we've got some kind of fantasy
variable length encoding that it
defaults to ascii
but it can escape out to do other
characters that are not in the ascii
data set when it needs to do so
so uh all non-ascii characters
represented as four bytes
well seems like that might not be all
that efficient
so maybe we should try it out and see
whether other things are also four bytes
so we'll get rid of that vargan hand
symbol let's replace it with
something a little easier to get on a
english keyboard
a pound sign so how's that represented
so we've got the original hello and
welcome hand symbol
and then we've got hello and we can see
that that pound sign is represented here
as
two bytes we can't see from this
particular representation what those
bytes are but there are two bytes there
so we've got single byte per character
representations we've got four byte per
character representations
we've got two bytes per character
representations for things that are
maybe a little bit more common than a
vulcan ham symbol
so that's actually quite an interesting
variable length encoding
but how is it done

so this variable length encoding of
unicode is
known as unicode transformation encoding
8 or utf-8
and it's 8 because it's encoded into
units of 8 bits or 1 byte
now to understand what's actually going
on with this
we should probably look at how various
different characters are
encoded so if we look at the letter a
the the unicode encoding for letter a
is in decimal it's 65 but
the way these are always expressed it's
not actually in decimal it's usually
expressed in a hexadecimal encoding
and so if you look it up in the utf
tables
this will end up as u plus zero zero
four one
and this four one is it is basically 65
decimal but in
a hexadecimal encoding now
let's look at some other characters as
well so the the usual british pound sign
um in unicode is u plus
zero zero a three
that one will actually encode relatively
concisely
um we've got the euro symbol which came
along a little bit later
and that is u plus 2
0 ac and we've got a smiley face
which we don't really care very much
about it's compact encoding and so
that's going to be u plus
1 f 6 0 0.
okay so those are some unicode
values these are the the the actual
numbers that represent these particular
characters in unicode
but how do we put these numbers into a
file in this variable length encoding
that's the question we're trying to
answer here
now before we do that i should probably
explain a little bit about the
relationship between
decimal hexadecimal and and binary
and why computer scientists use
hexadecimal all the time for
doing this stuff when base 16 isn't
necessarily the most natural thing to
think about in
in for humans we have 10 digits most of
us
and so we normally think about things in
base 10 but it turns out that when
dealing with things in computers
especially if you have to translate
to and from binary it's actually much
more convenient to represent things in
hexadecimal
and so to do that let's just look at
what the numbers
in are in binary and how they translate
to hexadecimal
so zero zero zero zero would be the
number zero
number one would be zero zero zero one
two is zero zero one zero and so forth

okay so those are the first 16 numbers
represented in binary down this column
and in hexadecimal in this column and so
what you can see
is that all the possible things we can
fit into four bits
go from 0 up to 15
and so there's a direct one-to-one
correlation between
four bits in binary format and a single
digit in hexadecimal format
and this means that it's very easy to
translate between hexadecimal
and binary we can simply if we want to
go over the binary
for six in hexadecimal it's the same as
a
6 in decimal no problem it's 1 1
0. like zero ones one two one four and
zero eight
but if we want to look at things that
are more than
nine then it becomes much more natural
to look at them in hexadecimal encoding
because 10 would be two digits um but
there's no
direct mapping in terms of the number of
digits in decimal
and the number of digits in binary
whereas there's a direct mapping
of four to one between the number of
digits in binary and the number of
digits in hexadecimal
so what this means is we can look at
these codes
in hexadecimal and immediately figure
out what they look like in binary
and that turns out to be very useful for
us so
if we look at for example um the a
character
and we just work from from right to left
1
in hexadecimal is going to be 0
0 0 1 and 4 in hexadecimal
is 0 1 0 0 and
this therefore is a in binary
that would be the 4 and that would be
the one in hexadecimal
but there's no direct translation to 65
in decimal so so this is much less
useful for us when we're trying to think
about converting between binary
and something that we can actually
usefully read because humans are not
very good at reading binary
similarly our euro character there
we've got a c which is here
one one zero zero
let's see an a
is one zero one zero
zero is zero zero zero zero
and the two
up here zero zero one zero
and so we can do is do this very easy
translation so now we
know what these things are in in binary
we now have to come down to
how do we actually encode these things
in utf-8
in a variable length encoding okay i've
shuffled all of those to one side to
pick a bit more space
now utf-8 says that
anything that would be representable in
7-bit ascii
just as encoded directly into into utf-8
so that's basically anything with 7 bits
has a 0 in the first bit of its utf-8
encoding
and then the other 7 bits just translate
through directly
or just three five six seven okay and
then
so that's a a single byte encoding
but if you can't fit it into seven bits
then we move on to two byte encodings
and in a two byte encoding in the first
byte
the first bit is always one to
distinguish
it from the from the single byte
encodings and then
the next two bits are one zero
and the reason why they're one zero
become apparent in a moment but it's
basically to distinguish it between the
three and the four byte encodings
and then we get five bits that we can
fit into there
and then we have to go into the second
byte and so
the we use a one zero as a
in the upper two bits to signal this is
a continuation of the previous
byte and then we can use six bits to
encode
the data that we want to encode one two
three four five six
okay so how does this represent with
with our particular characters here
well our a which was 41 in hex
can go into a single byte encoding so
that would be a zero in the first bit
and then the remaining digits the
remaining seven bits
the one is zero zero zero one
and the four in hex is
zero one zero zero but we don't have the
first zero so that's just one
zero zero and so that would be just the
the direct encoding
of the the letter a
now our pound sign
is 0 0 a3 okay
so now this doesn't quite fit into seven
bits
this zero zero a3 the three is
zero zero one one and the a is
one zero one zero so we've got eight
bits we need to stuff in here it doesn't
fit into seven bits
and so what we do is we switch to the
two byte encoding
so in the first byte we're going to have
a one one
zero and then five bits and in the
second byte we're going to have
one zero and then up to six bits
and so we can take these eight bits
we take the lowest six of them and put
them in here
one one zero zero
one zero so that's used up those ones
and then we can take the next two bits
and put them in here
one zero and then we we fill in with
zeros here
and so the pound encodes these two
bytes like this and that gives the two
byte encoding
if we want to go to something slightly
more complicated which is the euro
well that's going to be a three byte
encoding
and so to distinguish it from the two
byting codings it uses one one
one zero and then that only leaves us
with four bits left over there
and then the continuation bytes are the
same except we have two of them
and so to encode our euro our euro
was two zero ac
so working from right to left c is one
one
zero zero a is one
zero one zero zero is
just zeros and two
is zero zero one zero
okay so that's going to be our euro
symbol
and now we have to figure out how we
stuff these bits into the bytes
this is not going to fit into the the
number of bits we have left over for a
two bit encoding
uh one two three four five six seven
eight nine ten
eleven twelve thirteen fourteen to the
most significant one
and we can only get six plus five is
eleven so it doesn't fit into a two byte
encoding so we're gonna have to go to
three bytes
so that means that we know that these
are going to be one one one
and then we've got one one zero and
we've got four bits left over
and then we've got one zero and then
we've got six bits left over
six and then we've got another one zero
and we've got another six bits that we
can fit
there and so we basically just have to
copy these bits in
starting at the right hand side so
the first lower bits zero zero one
one zero one that's that chunk
then we start to copy in here zero one
zero zero zero zero so that's that chunk
these ones zero zero one zero will fit
in there
and that's the binary encoding for our
euro symbol fitting into three bytes
and so you can see that the basically we
just
extend that same pattern if we go out to
four bytes
one one one one zero so we only get
three left here
and then one zero and then we get
and we've got three of these so
i can't quite fit the one over there so
this is how we can actually create
variable length encodings and the nice
thing about this
is that if you look at any of the
bytes of the file you can you just have
to jump into the middle of the file and
look at a byte
are we at the beginning of a character
and if we get anything that starts in 0
or 1 1
0 or one one one zero or one one one one
zero um then we know that this byte is
the start of a character
and if we look in and we find anything
that starts with a one zero
we know that we're somewhere in the
middle of a character and we need to
move
back through the file to find the start
of that character
and so this means that we have variable
length encodings
the most common ones tend to be encoded
with short codes
the uncommon ones like our smiley tend
to be encoded with long codes
and wherever we jump into the file
we can figure out whether we're at the
start of a character and move on to the
next character or move back to the
previous character pretty easily
this is quite an elegant way to try and
stuff
basically codes which are sometimes
quite rare but quite we're
going to use large values for once and
that's quite common especially the
things that are
ascii because we've got so much legacy
of
bit ascii codes um on computers they end
up all encoding down to a single byte
and as a result we can have this sort of
how our k can eat it in the sense that
we can have these efficient codes for
things that occur a lot
and we can have slightly less efficient
codes for things that occur less often
and that's a pretty good compromise and
this is why utf-8 has ended up being the
the universal way for the internet and
for languages like python
to be able to encode text that can
incorporate any character set in the
world
including emojis

so we've seen how you can store text
even
text that includes emoji as a series of
numbers stored in bytes in computer
memory or on storage but
how do you store numbers i mean that
seems like a bit of a silly question
given that we've just been looking at it
but
really we've only seen how you store the
numbers from 0 to 255
in binary in individual bytes of
computer memory
but how do you store numbers that don't
fit in that range such as
257 or 3 billion or
minus 1 or even 0.25
how do you store those sort of numbers
in a computer so
let's look at that next let's start with
positive integers because they're the
easiest things to think about
is a little program that just prints out
numbers so it starts with number three
and multiplies by three each time
getting bigger and bigger and bigger
it just prints out what the decimal
number is and what the binary equivalent
is
and so you can see that as the
numbers are up between 0 and 255
we can get away with storing those
numbers in one byte of memory
if the number is between 256 and
65335 then
we can get away with storing that in two
bytes of memory
and similarly as we go up we need more
and more bytes of memory
and so when it comes to storing our
integers
we really just need to know what the
largest number we need to store is and
then we can figure out whether we want
to use
a one byte representation eight bits or
a 16-bit representation or a 32-bit
representation or a 64-bit
representation
and now python hides all this from you
but if you actually need to know how are
you manipulating in terms of the
instructions the cpu operates it needs
to know
what size of data it's operating on to
be able to do the right thing with it
python hiding that from you is very nice
from a programmer's point of view
in python you don't care how big an
integer is you can just use
any institute you want numbers no matter
how big they get python will be able to
cope with that
but if you come to store your data from
your python program
in a file now you're going to have to
actually pay attention to how large the
numbers are
because you're going to have to know how
many bytes in file to reserve for that
particular binary data
so you need to know whether you need
whether two bytes is going to be enough
or four bytes or eight bytes and so
forth
um you can't just get away with thinking
oh it's an arbitrary integer you can
just stuff it into the file
because when you read back from the file
you need to have
know how many bytes were used what the
representation was
so this is one of the things you need to
be careful of when you're actually
dealing with python
when you represent them in the computer
just in variables we don't need to care
very much but as soon as you start to
deal with the outside world
whether it's a file whether it's
transferring data over the network and
so forth you need to very much care
about the representation
and the first thing you need to care
about is how many bytes are we using to
represent our integers
now let's take a look at this particular
number
252 million 117
to 761. now why have i picked that
number
i picked it because it makes a nice
pattern there's
one one bit set in the least significant
byte
there are two one bit set in the next
byte there are three one bit set in the
third byte
and there are four one bit set in the
fourth byte
now when we store this in computer
memory
what order are the bytes stored
so just how do you lay out this number
in memory
well it turns out that as with many
things
the computer scientists fell into
two camps in terms of how they thought
about the problem
now in the first camp there are people
who say well
okay let's just visualize how
memory is laid out and so if we divide
this into
bytes of memory
where this is sort of the first byte in
memory this is the second byte and third
and fourth and so forth
how would you put this number in it well
it's pretty obvious how you put this
number in there
you just copy it straight in so that one
would be one
zero zero whatever this one would be one
one zero zero whatever this will be one
one one
zero zero and this will be one one one
one zero zero zero and so that's the
obvious way to put this number into
memory
the largest byte the light
goes at the first in memory and then
they go towards the least significant
byte
and that's the obvious way to lay things
out in memory because you just want to
copy these bits
straight into memory like that and so
that's the camp that
that are now known as the big endians
and they learned the big engines because
the big end of the
number goes first in memory now
that's one way of thinking about the
problem but
unfortunately it's not the only way of
thinking about the problem
because there's also a different camp
who thinks that no you don't write
memory out like this
you just think about memory as being a
whole series
of bytes that we can draw going down the
board
and so this is the first byte in memory
and this is the second and this is the
third and this is the fourth and so
forth
and now the obvious thing to do is to
well we don't
sometimes we're going to need one byte
of memory sometimes we're going to need
two bytes in memory sometimes we're
going to need four bytes in memory
so we'll just take this and we'll put it
into the first of these bytes
and then we'll kind of overflow from
that around to the second one if we need
the space
and then we'll put that one into here
and then we'll overflow from that one
round to here if we need the space and
then we'll go
that and then we'll overflow from there
and so
what we end up with is the number
basically starting wherever it starts
and carrying on through depending on how
many bytes of memory it actually needs
and so that means that
the first thing in memory is this end of
the integer
and the second one in memory is this
byte of the integer and the third one in
memory is this byte of the inter and the
fourth row memory is this byte of the
integer
and so in this case the little end goes
first and so these are known as little
endians
now none of this matters so long as
your data stores it stays in the memory
of the computer
but as soon as you actually want to
transfer information between
computers now you need to know
when you're sending an integer across
the network
is the first byte of the integer the big
end or is the first byte of the integer
the little end
and if you don't know what you're how
you're sending it
then a computer that stores it in this
way won't be able to talk to a computer
that stores it in this way
and this of course became a big issue in
the 1970s going into the 1980s when the
internet suddenly started to come along
before that it didn't really matter
and so there were religious wars fought
over this issue
and in the end the big endians won
and the network byte order is defined as
big endian
the big end of your numbers goes first
and that sort of made sense at the time
because the dominant computers things
like pdp-11s
and so forth were big endian computers
now things would probably have ended
there except for the fact that
this company called intel made some
processes that turned out to be
reasonably successful
and so the intel x86 processors
unfortunately
they were little endian and so
pretty much every computer these days is
an intel x86 processor unless it's arm
like on your phone
and so the computers that dominate the
internet
now unfortunately have a different byte
order
to the computers that dominated the
internet in its early days
and so whenever you want to take an
integer that's stored
on your computer and transfer it across
the internet you have to shuffle the
bytes around
to get it into network byte or to
transfer it across the network to
shuffle the bytes back again at the
other end
it turns out that arm which make the
processors or design the processors that
are in your phone
and so forth um they actually designed
their process so they could either be
big engine or little engine there's ways
to actually set the processor up so they
could do either way around
but pretty much all arm processors that
are that are used in your phones these
days
are configured so that they work in
little endian order
so we've ended up with this strange
situation where network byte order is
defined as something that's different
from
the byte order of pretty much every
computer that's used on the internet
today
and that's not necessarily the best
situation we could have been in
so far we've seen that if you want to
store
integers we're going to have to pay
attention to two things
the first thing we're going to have to
pay attention to is
how many bytes do we need do we need to
use
one two four or eight bytes typically to
be a power of two
um depending on what range of numbers we
want to be able to hold
the second thing we've seen is that if
you want to store
integers that require more than one byte
we have to pay attention to the byte
order
i'll be using a big endian
representation or we're using a little
engine representation
but there's one more thing we need to
pay attention to
so far we've only looked at what happens
with positive integers
what are we going to do about negative
integers
suppose we're trying to store for
example the number
-13 the positive number 13
is if we use just say an 8-bit
representation
is 0 0 0 0 1 1 0 1.
it's 12 plus 4 plus 1. but how do we
represent
-13 well it turns out that over the
years computers have used
three main different representations for
negative numbers
the the first way they've done is
something called
sign and magnitude which is they simply
steal the most significant bit
and if the most significant bit is a
zero
then the number is a positive number and
if the most significant bit
is a one then the number is a negative
number
and that's it and this has the main
advantage of just being very very simple
we can easily see what's going on
it does have some slight problems though
when it comes to actually how we do
arithmetic
we have to treat negative numbers
somewhat differently from positive
numbers
so it requires extra hardware the
second way that computers have used to
represent negative numbers is known as
one's complement
and so if we want to convert from say 13
to
-13 all we need to do here is simply to
flip
every single one to be a zero and every
single zero to be a one
and so the -13 is just the complement of
13.
now this works reasonably well but there
are some some minor wrinkles
um one particular thing to note is that
there are two zeros
there's positive zero which is where all
of the binary bits are zero
and there's the complement of it which
is where all the binary digits are ones
and the fact that we've got two zeros
means that
if we're counting up or counting down
there's a bit of a discontinuity
around the point of zero and that makes
math just a little bit harder for the
hardware
so that brings us to the third way of
storing negative numbers which is
two's complement so if we had this
problem with there being
two zeros we can solve that problem
instead of by
just turning every one into a zero and
every zero into a one
we do that and then we add one to the
result and that's what's known as two's
complement
now this might seem slightly strange
thing to do but
you can immediately sort of see that if
it sort of solves the problem of having
two zeros because
if we add one to a number where all of
the digits are one
that's going to carry up through the
digits to get to the maximum one and
turn it into a zero so we've only got
one
zero now rather than two
now it has some sort of nice properties
so the first thing to note
is that if we add minus 13
to plus 13 we end up with
2 to the power n where n is the number
of bits we're using in this case we end
up with 2 to the power 8.
but this is true for any pair of numbers
if you add a num
positive number to its negative
equivalent we're always going to end up
with 2 to the power n
now why is that an interesting thing
well we can sort of flip this around and
we can say well okay
if we want to go from a positive number
to negative equivalent we can just
subtract it
from 2 to the power n that has exactly
the same thing as flipping all the bits
adding 1.
now this immediately then shows us that
we've got
um some interesting properties so
if you want to go from the most positive
number that you can represent so that's
a zero and then every other bit is a one
and we add one to that so if we go
counting up counting up counting up we
get to the most positive number we want
to store and we add one to it
it's going to flip from basically the
most positive number we want to store
into the most negative number we can
store in this particular case it would
go from
127 to minus 128.
but something slightly more interesting
than that which is that what happens
around the zero point when we're
counting up so
let's have a look at how we still say
minus 3
minus 3 is represented in this way okay
so what happens if we want to count up
by 1. so we
want to add 1 to that do we have to do
anything special to do
arithmetic with negative numbers well it
turns out no we don't
if you just do exactly the same
arithmetic you did for positive numbers
the normal way we add binary digits we
go from minus three to minus two like
that
okay so we can add another one and we go
from minus two
to all of the binary digits being one
and that's minus one
and what happens if we want to add one
again well
if we add one to this it's going to
carry all the way up into the ninth
bit but we don't have nine bits so that
would get thrown away
so if we add one to all of the ones it's
going to go to
all the zeros which is our
representation of zero so it's just
magically done the right thing
and we can keep counting up and so forth
with positive numbers but we know that
works
so the really cool thing about this
two's complement representation
is that all of the basic operations
addition
subtraction multiplication and so forth
are exactly the same
for negative numbers as they are with
positive numbers in fact the computer
hardware
doesn't even have to care that it's a
negative number it doesn't even have to
know it's a negative number
just addition subtraction multiplication
just do the right thing
so it the actual computer cpu
has no idea whether it's adding negative
numbers or positive numbers
all that down to is how it's interpreted
by higher level software is it
interpreted as
being a negative number if it's
sufficiently large or is it interpreted
as being a positive number
but the hardware doesn't have to care so
this is a very nice property and
this means that pretty much all modern
computer hardware
uses this representation which is two's
complement representation
to store negative numbers and
so it's very cute in terms of how the
hardware simply doesn't have to know
that it's actually negative or positive
the right arithmetic happens
irrespective of whether it's positive or
negative
now if we've got some integers in our
python code and we want to actually
write them out to a binary file or write
imagine a binary format to a network
connection
then we're going to have to actually
tell python
how to convert those integers what
representation to use
and so suppose we've got this integer
here
1027 and we want to convert it
into a binary representation in order to
restore it to a file
we have to use this two bytes function
to convert from an integer into
a set of bytes suitable for writing out
into the file
and we have to tell it how to do it so
the first thing we have to do is return
how many bytes to use in this case 1027
will fit into two bytes
so that's just fine and we also have to
tell it the byte order which way round
we're going to put the bytes in this
case we're saying we need to be big
endian
and by default it will default to saying
this is an
unsigned integer but if we want to
assigned integer we're going to have to
tell python that too
if we wanted to do it as four bytes we
could specify four bytes if we wanted to
do it
as being little endian instead of big
endian we can do that too
we've got a number that doesn't fit into
four bytes or even into eight bytes
so here we've got 2 to the power of 65
that won't even fit into 8 bytes
so we can tell python can you do this as
an industry but use 10 bytes please
and it can do that too and if we want to
store
say 1027 here we can do two bytes we can
say maybe we want to store it as four
bytes
but this is going to be a signed number
now and so
use your two's complement signed wrist
scientific to do that
so all of these are basically all the
different ways we can
figure out how to actually represent
integers
specifying the number of bytes the byte
order and whether it's signed or
unsigned the three things we need to
actually tell python how to do
now of course it's possible you can do
this with a value that can't be
represented
so if we try to say store 65536
which is just too big to fit into 16
bits
in two bytes it's going to cause an
error
and so python will actually throw a
overflow exception in this particular
case and hopefully we'll get an error
there
and similarly if we want to store three
two seven
six eight which is one too large to
store
as a signed 16 potential you can store
it as an unsigned one but we can't try
it as a signed integer
that will also cause an overflow error
so
these are basically the conversion
functions you need if you want to
actually run
um tell python to store your integers in
a file or you want to talk python to put
them in a binary representation to
transmit across a network connection
so let's run this
so what we can see here is that um
if we store 1027 as two bytes big endian
this is saying this is a stream of bytes
this is just how python represents byte
strings when you ask it to print it
and the first one of those bytes we've
got hex four and the second one of those
bytes
we've got hex three and that's because
1027
is basically number four
in the the largest bits it's the
first bit of the upper bike would be 256
the second one is 512 in the third one
1024
1024 is that in the upper byte
and 1024 plus three gives us a thousand
twenty seven so that's actually the
correct representation of that big
engine
the thousand twenty four part comes
first because it's big endian
and the three comes second we want to
store it as four bytes then
first upper two are going to end up zero
because we didn't really need them
but if we want to store it as four bytes
little endian then everything flips
around
the three comes first then the thousand
and twenty four and then
the additional more significant zeros we
don't really care about those
and and so forth so if we then look at
the negative values here
1027 is four bytes negative
signed then we can see that most of the
bits end up as as one because a thousand
and twenty four is actually
um because the 27 is a fairly small
number
compared to how we restore things in in
four bytes so all the upper bytes end up
with
one one one one one because we've
wrapped around and we're
pretty close to getting back towards
zero now
and then if we try to store six five
five three six in two bytes
well it does correctly cause that
overflow exception and similarly if we
want to store three two
seven six eight in two signed bytes that
also causes
our um overflow exception
so so that's how we tell python to
convert from integers
to a set of bytes suitable for storing
to a file or transmitting across a
network

so we're almost done but not quite
there's
one more thing we need to know how to do
what happens if we want to store
numbers which aren't integers we want to
store 0.25
or 0.3 or numbers like that
how do we store that kind of number
well it turns out that computer hardware
pretty much
all implements a standard called ieee
floating point arithmetic
and so we should understand a little bit
about how that works too
so the first thing to note is that we
can use a point in the same way we use
decimal point in decimal
in binary as well so if we want to
represent the number
2.25 which is in decimal we want to
represent in binary
well the number 2 in binary is 1 0
and 0.25 well
we have next column after the point
would be
a halves column we don't have any of
those and then the next
column after that would be the quarters
column and we have one of those
so 2.25 in decimal is 1 0.01
in binary using a binary point
okay so we could use a binary
fixed point notation in this but then we
have to figure out how many bits we have
to the right of the binary point and how
many bits we have to the left of the
binary point
and that is pretty limiting when we
actually want to
to represent numbers we don't
necessarily know in advance or want to
have to specify in advance
exactly how many bits there are in each
half of our number
so what's the alternative well
when we do this in decimal we use
scientific notation so
you can say if we have 1 2 3 4.5
we can put this in binary in
scientific notation as 1.2345
times 10 to the power of 3.
and so we can use precisely this way of
representing numbers
to represent our binary numbers too
so if we've got one 0.01
in binary then we can represent that in
canonical form
as 1.001 times
2 to the power in this case 1.
so this is what we can do we can take
our numbers and we can represent them in
this
binary version of scientific explanation
x
scientific notation where we have
a number here which always has a one
before the binary point and then some
number of
places after it um times two to the
power of some exponent
so now all we need to do is figure out
how many bits we need for this piece
and how many bits we need for the
exponent
so this brings us to ieee 754 floating
point representation
and so this is a standard for how to
represent
floating point numbers in computers
and ieee 754 specifies this for 32-bit
floating point numbers there's also a
version for 64-bit floating point
numbers which
pretty much works the same just with
bigger fields
so how are we going to put our 1.001
times 2 to the power 1
into these bits well the first thing we
need to do is figure out how many bits
we're going to have
for the mantissa and how many bits we're
going to have for the exponent
and we're also going to have to figure
out how we're going to represent
negative mantissas and negative
exponents because we're going to have to
be able to cope with those two if we
want the number to be very small we need
negative exponents
and if we want to have the full range of
numbers we want to be able to represent
we need to be able to have negative
mantissa
so what i triple e floating point does
is first of all it
it carves out the very top bit here and
says that's a sign bit
if that bit is zero then it's a positive
number
and if that bit is one then it's a
negative number
the next thing they do is they carve out
the next eight bits
so we've got eight bits here
and this is the exponent
which leaves the remaining 23 bits
to be the mantissa
but how exactly are we going to encode
the mantissa and the exponent into these
legs
well let's first of all deal with the
mantissa because it's slightly
simpler the first thing we realize is
that actually for
any number we want to store there's
always going to be a one
to the left of the point here and so we
don't actually need to store that
we can just have that implied the only
exception for z
is zero and then we can have special
case for zero
and by doing this we can save ourselves
a bit
so when we store the mantissa here in
these 32 bits
we assume that the one is there
and then we just write the remaining
bits so that zero zero
one would end up here and the rest of
the bits will all end up as
zeros because we don't actually need any
more precision than that so that's the
first part that's how we store the
mantissa
now the next question is how do we
extort how do we store
the exponent now the problem here of
course is that we need to be able to
store very big numbers with large
positive exponent and we had to store
very small numbers with
negative exponents and so we're going to
have to figure out how we actually store
that in here
now we could go for some kind of two's
complement notation but that's actually
a little more complicated than we really
need for this particular case
so what all ieee did is to say that
we're just going to add
in hex 7f or 127
in decimal to the value of the exponent
before we store it in here
and that's just shifting the values so
that we can get a range
of values so if we want to store the
exponent of 1 in here
we add it to 127 we get 128
and 128 in binary is one and then
seven zeros and that's
exactly how we store 2.25
in an ieee floating point number
using 32 bits now we know how
floating point numbers are stored let's
have a look at them in python
now what we've looked at on the
whiteboard was
floating point numbers that are 32-bit
if you'd use the float type in c you'll
get a 32-bit floating point number
if you use the double type in c you'll
get a 64-bit floating point number
and it's actually the 64-bit version of
the floating point that python uses for
for its floating point numbers but we
can actually have a look
and and ask python what exactly are you
using
how big are the different fields and you
can do this by
if you just import this and then print
out sys.float info
it will tell you everything you want to
know about how floating point numbers
are actually represented
on your particular computer which might
differ if you from other computers if
you've got a different cpu
and so we can run this we can run
code and see what it gives us
there we go and so what this is telling
us is that
the the range of exponents that you can
store for example it can say that the
largest exponent it can store
is 1024 so 2 to the power of 1024 is
sort of roughly the largest things it
can do the minimum exponent it can store
is uh minus 1021.
um it tells us that the the mantissa
in this particular representation uses
53 bits so that gives you some idea of
the precision
and actually if you really want to know
what the best possible precision is
epsilon here is the smallest possible
difference
that you can represent in floating point
numbers
in this particular implementation of
floating point
so that gives you an idea of what the
maximum precision is and maximum range
you can represent it
so it would seem then that floating
point numbers are this
really useful convenient way of
representing
any numbers you want to represent and
because you can represent
fractional numbers they're probably
better than integers
but you've got to be quite careful when
you use floating point
numbers um because sometimes that
limited precision is going to come back
and bite you
so what do i mean by that well let's
just
write some code so what i want to do is
i'm going
to do for i in range
up to let's say 20.
and what am i going to do i want to just
print out what happens if i
take i and divide it by a hundred so
that single slash is going to
give us floating point division in
python 3 and i'm going to multiply that
by 100 again
so
take i divide it by 100 multiply by 100
we really ought to be able to get back
where we started shouldn't we
and so what happens if we run that
well let's have a look
well some of the numbers came back where
they were supposed to
but 7 and 14 did not
and so well what's going on here
well we've only got a limited number of
bits
and so if you try to represent
7 divided by 100 in binary floating
point numbers
what we end up with is a recurring
decimal but as there's a limited number
of bits it gets truncated and then we
multiply it back by 100 and we don't
quite get back to where we started
it's exactly the same thing that would
happen if for example we try to divide
10 by 3 and wrote it down as a decimal
and then took that written down number
and multiplied it back up
you can only write down 3.3333
some number of times whatever number of
times you do when you multiply it back
up you're not going to get to exactly
the same place as where you started from
and so there's a rounding error that can
happen there and that rounding error can
definitely happen
in in 13 point numbers as well
now does it always round back to the
same number
um well let's have a look at that
um so let's just store this result
um and i wanted to see whether we
always get back to the same integer even
we'll go up to 100 this time
and so what i want to do is i'll say if
um i
is is not equal to
that result rounded back to an integer
then we're going to print out what we
got we're going to print out i we're
going to print out the result
and we're going to print out what
integer it rounded to is
okay and one square bracket there
okay and so if we run this
are we gonna get some numbers that come
back to different integers even
and the answer is yes um if i take 29
and divide it by 100 and then multiply
it by 100 and then round it back
to the nearest integer again well we
just round it to an integer it's not the
nearest integer because
when you do an int conversion from a
float in python
it rounds down um so we divide it and we
end up with something just a little bit
less than 29 and then we convert it back
to an inch and it ends up as 28.
so if i take
integer 29 divide it by 100
multiply it by 100 and convert it back
to an integer i don't end up back where
i started
and so this is just one example of
you've got to be quite
careful when you're doing floating point
arithmetic because you will get
some truncation of the precision
especially if you have recurring
binary equivalent of decimals and
they will get truncated they will get
rounded and we don't necessarily always
get back to where we started
so you just have to be aware of there's
there's a bunch of gotchas associated
with precision
in in floating point numbers so if
you're kind of calculating something and
expecting it to end up
at exactly some value and you're
comparing it with that for equality you
might not get exactly that value if
you've got
some rounding errors going on so this is
the main thing to be concerned with when
you do floating point arithmetic
in any programming languages including
python is that there's going to be some
rounding errors happen sometimes
and so you might not necessarily get
exactly the number you might have
expected from
pure maths and you need to be careful
with that
and allow some leeway for potential
rounding errors that might happen
but other than that floating point
numbers are extremely convenient and we
use them all the time
but you do need to know the gotchas
so we've covered quite a lot in this
video we've covered
how you represent textual information
we've covered the basics of simple ascii
representations all the way through to
how you represent text in in any
language of the world using unicode
and how to then encode that unicode into
utf-8 encodings which is what python
uses natively
and what most of the internet uses
natively for for internationalization
we've also looked at how do you
represent
numbers and the difficulty with how you
might say
what the representation of integers is
when we store them to files or transfer
them over the network
we've also looked at floating point
numbers how they're represented
how they're stored and a few of the
gotchas associated with how you actually
might use them in the real world
so that's it for this video see you next
time

